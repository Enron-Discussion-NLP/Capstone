{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e0840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import email\n",
    "from email.parser import Parser\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import acquire\n",
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a462997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a504d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r'\\n\\n.*\\n', df.message[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b81e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email.parser import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = df.message[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f884d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = Parser().parsestr(message)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5526e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers['From'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7808e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e456e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers['To'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers['Message-ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5003af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = []\n",
    "dates = [] \n",
    "for i in df.message:\n",
    "    headers = Parser().parsestr(i)\n",
    "    body = headers.get_payload()\n",
    "    date = headers['Date']\n",
    "    bodies.append(body)\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de632db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777fb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68228a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_df = pd.DataFrame(bodies, columns = ['content'])\n",
    "dates_df = pd.DataFrame(dates, columns = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6abb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "body_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba20cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = body_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae76551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_emails = []\n",
    "to_emails = []\n",
    "subjects = []\n",
    "for i in df.message:\n",
    "    headers = Parser().parsestr(i)\n",
    "    from_email = headers['From']\n",
    "    to_email = headers['To']\n",
    "    subject = headers['Subject']\n",
    "    from_emails.append(from_email)\n",
    "    to_emails.append(to_email)\n",
    "    subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_email_df = pd.DataFrame(from_emails, columns = ['from_email'])\n",
    "to_email_df = pd.DataFrame(to_emails, columns = ['to_email'])\n",
    "subjects_df = pd.DataFrame(subjects, columns = ['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a077c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959489cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['from_email'] = from_email_df\n",
    "df['to_email'] = to_email_df\n",
    "df['subject'] = subjects_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe41841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d567be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Acquire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_email():\n",
    "    'This functions will get us contents of email and from email, to email and subject'\n",
    "    \n",
    "    # pandas helping us to read csv file\n",
    "    df = pd.read_csv('emails.csv')\n",
    "    \n",
    "    # empty list for keeping contents\n",
    "    bodies = []\n",
    "    \n",
    "    # empty list for keeping dates\n",
    "    dates = []\n",
    "    \n",
    "    # empty list for keeping emails from\n",
    "    from_emails = []\n",
    "    \n",
    "    # empty list for keeping emails to\n",
    "    to_emails = []\n",
    "    \n",
    "    # empty list for keeping subjects from\n",
    "    subjects = []\n",
    "    \n",
    "    # loop to add content, date, From, To, Subject in an empty list\n",
    "    for i in df.message:\n",
    "        headers = Parser().parsestr(i)\n",
    "        body = headers.get_payload()\n",
    "        date = headers['Date']\n",
    "        from_email = headers['From']\n",
    "        to_email = headers['To']\n",
    "        subject = headers['Subject']\n",
    "        bodies.append(body)\n",
    "        dates.append(date)\n",
    "        from_emails.append(from_email)\n",
    "        to_emails.append(to_email)\n",
    "        subjects.append(subject)\n",
    "            \n",
    "    # making DatFrame out of list created by lopp\n",
    "    body_df = pd.DataFrame(bodies, columns = ['content'])\n",
    "    dates_df = pd.DataFrame(dates, columns = ['date'])\n",
    "    from_email_df = pd.DataFrame(from_emails, columns = ['from_email'])\n",
    "    to_email_df = pd.DataFrame(to_emails, columns = ['to_email'])\n",
    "    subjects_df = pd.DataFrame(subjects, columns = ['subject'])\n",
    "    \n",
    "    # giving a name to the column created in DataFrame\n",
    "    df['content'] = body_df\n",
    "    df['date'] = dates_df\n",
    "    df['from_email'] = from_email_df\n",
    "    df['to_email'] = to_email_df\n",
    "    df['subject'] = subjects_df\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= acquire_email()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed = df.drop(columns = ['file', 'message', 'from_email', 'to_email', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed.to_csv('content_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b85a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new =pd.read_csv('content_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f235a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  \\\n",
       "0           0                          Here is our forecast\\n\\n    \n",
       "1           1  Traveling to have a business meeting takes the...   \n",
       "2           2                     test successful.  way to go!!!   \n",
       "3           3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4           4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                    date  \n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquire.acquire_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feeb48f",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ab092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(s):\n",
    "    '''\n",
    "    Takes a string and returns a normalized lowercase string \n",
    "    with special characters removed\n",
    "    '''\n",
    "    # droping \\n\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = s.replace('\\t', ' ')\n",
    "   \n",
    "    # strip\n",
    "    s = s.strip()\n",
    "    # lowercase\n",
    "    s = str(s.lower())\n",
    "    # normalize\n",
    "    s = unicodedata.normalize('NFKD', s)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    # remove special characters and lowercase\n",
    "    s = re.sub(r\"[^a-z0-9'\\s]\", '', s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean(df_new.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a209eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean(df_new.content[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean(df_new.content[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce995c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    '''\n",
    "    Takes a string and returns a tokenized version of the string\n",
    "    '''\n",
    "    # create tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # return tokenized string\n",
    "    return tokenizer.tokenize(s, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c32730",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(df_new.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(df_new.content[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8931289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_string_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    Takes in a dataframe, original string column, with optional lists of words to\n",
    "    add to and remove from the stopword_list. Returns a dataframe with the title,\n",
    "    original column, and clean, stemmed, and lemmatized versions of the column.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean).apply(tokenize).apply(remove_stopwords, extra_words=extra_words, exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df['clean'].apply(tokenize).apply(stem)\n",
    "\n",
    "    df['lemmatized'] = df['clean'].apply(tokenize).apply(lemmatize)\n",
    "\n",
    "    \n",
    "    return df[['title', column, 'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d281d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['date', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d46e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>forecast</td>\n",
       "      <td>forecast</td>\n",
       "      <td>forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>traveling business meeting takes fun trip espe...</td>\n",
       "      <td>travel busi meet take fun trip especi prepar p...</td>\n",
       "      <td>traveling business meeting take fun trip espec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>test successful way go</td>\n",
       "      <td>test success way go</td>\n",
       "      <td>test successful way go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>randy send schedule salary level everyone sche...</td>\n",
       "      <td>randi send schedul salari level everyon schedu...</td>\n",
       "      <td>randy send schedule salary level everyone sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>let ' shoot tuesday 1145</td>\n",
       "      <td>let ' shoot tuesday 1145</td>\n",
       "      <td>let ' shoot tuesday 1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517396</th>\n",
       "      <td>Wed, 28 Nov 2001 13:30:11 -0800 (PST)</td>\n",
       "      <td>This is a trade with OIL-SPEC-HEDGE-NG (John L...</td>\n",
       "      <td>trade oilspechedgeng john lavorato ' book john...</td>\n",
       "      <td>thi trade oilspechedgeng john lavorato ' book ...</td>\n",
       "      <td>trade oilspechedgeng john lavorato ' book john...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517397</th>\n",
       "      <td>Wed, 28 Nov 2001 12:47:48 -0800 (PST)</td>\n",
       "      <td>Some of my position is with the Alberta Term b...</td>\n",
       "      <td>position alberta term book send positions dire...</td>\n",
       "      <td>posit alberta term book send onli posit direct...</td>\n",
       "      <td>position alberta term book send position direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517398</th>\n",
       "      <td>Wed, 28 Nov 2001 07:20:00 -0800 (PST)</td>\n",
       "      <td>2\\n\\n -----Original Message-----\\nFrom: \\tDouc...</td>\n",
       "      <td>2 original message doucet dawn sent wednesday ...</td>\n",
       "      <td>2 origin messag doucet dawn sent wednesday nov...</td>\n",
       "      <td>2 original message doucet dawn sent wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517399</th>\n",
       "      <td>Tue, 27 Nov 2001 11:52:45 -0800 (PST)</td>\n",
       "      <td>Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...</td>\n",
       "      <td>analyst rank stephane brodeur 1 chad clark 1 i...</td>\n",
       "      <td>analyst rank stephan brodeur 1 chad clark 1 ia...</td>\n",
       "      <td>analyst rank stephane brodeur 1 chad clark 1 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517400</th>\n",
       "      <td>Mon, 26 Nov 2001 10:48:43 -0800 (PST)</td>\n",
       "      <td>i think the YMCA has a class that is for peopl...</td>\n",
       "      <td>think ymca class people recovering heartattack...</td>\n",
       "      <td>think ymca ha class peopl recov heartattack re...</td>\n",
       "      <td>think ymca ha class people recovering heartatt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517401 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         date  \\\n",
       "0       Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
       "1        Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
       "2       Wed, 18 Oct 2000 03:00:00 -0700 (PDT)   \n",
       "3       Mon, 23 Oct 2000 06:13:00 -0700 (PDT)   \n",
       "4       Thu, 31 Aug 2000 05:07:00 -0700 (PDT)   \n",
       "...                                       ...   \n",
       "517396  Wed, 28 Nov 2001 13:30:11 -0800 (PST)   \n",
       "517397  Wed, 28 Nov 2001 12:47:48 -0800 (PST)   \n",
       "517398  Wed, 28 Nov 2001 07:20:00 -0800 (PST)   \n",
       "517399  Tue, 27 Nov 2001 11:52:45 -0800 (PST)   \n",
       "517400  Mon, 26 Nov 2001 10:48:43 -0800 (PST)   \n",
       "\n",
       "                                                  content  \\\n",
       "0                               Here is our forecast\\n\\n    \n",
       "1       Traveling to have a business meeting takes the...   \n",
       "2                          test successful.  way to go!!!   \n",
       "3       Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                     Let's shoot for Tuesday at 11:45.     \n",
       "...                                                   ...   \n",
       "517396  This is a trade with OIL-SPEC-HEDGE-NG (John L...   \n",
       "517397  Some of my position is with the Alberta Term b...   \n",
       "517398  2\\n\\n -----Original Message-----\\nFrom: \\tDouc...   \n",
       "517399  Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...   \n",
       "517400  i think the YMCA has a class that is for peopl...   \n",
       "\n",
       "                                                    clean  \\\n",
       "0                                                forecast   \n",
       "1       traveling business meeting takes fun trip espe...   \n",
       "2                                  test successful way go   \n",
       "3       randy send schedule salary level everyone sche...   \n",
       "4                                let ' shoot tuesday 1145   \n",
       "...                                                   ...   \n",
       "517396  trade oilspechedgeng john lavorato ' book john...   \n",
       "517397  position alberta term book send positions dire...   \n",
       "517398  2 original message doucet dawn sent wednesday ...   \n",
       "517399  analyst rank stephane brodeur 1 chad clark 1 i...   \n",
       "517400  think ymca class people recovering heartattack...   \n",
       "\n",
       "                                                  stemmed  \\\n",
       "0                                                forecast   \n",
       "1       travel busi meet take fun trip especi prepar p...   \n",
       "2                                     test success way go   \n",
       "3       randi send schedul salari level everyon schedu...   \n",
       "4                                let ' shoot tuesday 1145   \n",
       "...                                                   ...   \n",
       "517396  thi trade oilspechedgeng john lavorato ' book ...   \n",
       "517397  posit alberta term book send onli posit direct...   \n",
       "517398  2 origin messag doucet dawn sent wednesday nov...   \n",
       "517399  analyst rank stephan brodeur 1 chad clark 1 ia...   \n",
       "517400  think ymca ha class peopl recov heartattack re...   \n",
       "\n",
       "                                               lemmatized  \n",
       "0                                                forecast  \n",
       "1       traveling business meeting take fun trip espec...  \n",
       "2                                  test successful way go  \n",
       "3       randy send schedule salary level everyone sche...  \n",
       "4                                let ' shoot tuesday 1145  \n",
       "...                                                   ...  \n",
       "517396  trade oilspechedgeng john lavorato ' book john...  \n",
       "517397  position alberta term book send position direc...  \n",
       "517398  2 original message doucet dawn sent wednesday ...  \n",
       "517399  analyst rank stephane brodeur 1 chad clark 1 i...  \n",
       "517400  think ymca ha class people recovering heartatt...  \n",
       "\n",
       "[517401 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = prep_article_data(df_new, 'content')\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2eb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.to_csv('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new['content'].apply(basic_clean).apply(tokenize).apply(remove_stopwords, extra_words=extra_words, exclude_words=exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df df_new['content'].apply(basic_clean).apply(tokenize).apply(remove_stopwords)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7256394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              forecast\n",
       "1     traveling business meeting take fun trip espec...\n",
       "2                                test successful way go\n",
       "3     randy send schedule salary level everyone sche...\n",
       "4                              let ' shoot tuesday 1145\n",
       "                            ...                        \n",
       "95    mac thanks research report eog observation gas...\n",
       "96    forwarded phillip k allenhouect 08202000 0539 ...\n",
       "97    forwarded phillip k allenhouect 08202000 0538 ...\n",
       "98    forwarded phillip k allenhouect 08202000 0538 ...\n",
       "99    checked exercising option smith barney enron h...\n",
       "Name: lemmatized, Length: 100, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['lemmatized'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6903bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_string_data(df_new, df_new.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de641e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
